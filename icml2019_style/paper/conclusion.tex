\section{Conclusion}
We introduce an adversarial framework to enforce compositional fairness constraints on graph embeddings. 
Our approach uses a bank of adversarial filters to optionally enforce fairness constraints over a set of possible sensitive attributes.
Our work sheds light on how fairness can be enforced in graph representation learning, and our compositional approach highlights how fairness could be deployed in a real-word, user-driven setting, where it is necessary to optionally enforce a large number of invariance constraints over learned graph representations.
%Our preliminary results highlight the tradeoff between the flexibility afforded by this compositional approach, and the model performance. 